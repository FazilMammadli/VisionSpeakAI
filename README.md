# ğŸ–¼ï¸ VisionSpeakAI - Image-to-Speech GenAI ğŸ™ï¸ğŸ”¥  
AI-powered tool that **analyzes an image** and **converts it into a narrated short story** using **LLMs (Large Language Models)** and **AI-powered TTS (Text-to-Speech)**.  

ğŸš€ **Powered by:** Hugging Face AI, OpenAI, LangChain, and Streamlit.  
ğŸ¯ **Use Cases:** Accessibility, storytelling, content generation, and AI-powered narration.

---

## ğŸŒ **Live Demo**  

ğŸ”¹ **Run App with Streamlit Cloud**  
[ğŸš€ Launch on Streamlit](https://image-to-speech-genai-tool-using-llm.streamlit.app/)

ğŸ”¹ **Run App with Hugging Face Cloud**  
[ğŸš€ Launch on HuggingFace Space](https://huggingface.co/spaces/GurpreetKJ/Image-to-SpeechStory_GenAI-Tool)

---

## ğŸ¥ **How It Works (Demo)**
ğŸ–¼ï¸ Upload an image â†’ ğŸ¤– AI generates a **short story** â†’ ğŸ”Š AI **narrates the story**  

![System Overview](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DzN_iN8hDKK3pTtjElF_Qw.png)  

ğŸ“Œ **Example Output:**  
![Family Test Image](img-audio/VisionSpeakAI.jpg)  

ğŸ§ **Listen to the AI-generated narration** in the `img-audio` folder.

---

## ğŸ— **How It Works (System Design)**  
![System Flow](img/system-design.drawio.png)  

### **ğŸ”„ AI Workflow**
1ï¸âƒ£ **Image-to-Text** â†’ AI extracts the meaning/context from the image.  
2ï¸âƒ£ **Text-to-Story** â†’ OpenAI's GPT-3.5 Turbo generates a **creative short story**.  
3ï¸âƒ£ **Story-to-Speech** â†’ AI converts the story into **natural-sounding speech**.  
4ï¸âƒ£ **User Interaction** â†’ Upload an image, listen to the generated story.

---

## âš¡ **Features**
âœ… **AI-powered Image Understanding** (Hugging Face Transformer)  
âœ… **Creative Story Generation** (GPT-3.5 Turbo)  
âœ… **Human-like Speech Synthesis** (Hugging Face TTS)  
âœ… **Multi-Language Support** (Customizable for different languages)  
âœ… **Web-based UI with Streamlit**  

ğŸ“Œ Example:  
![Picnic Test Image](img-audio/PicnicOutput_.jpg)  

ğŸ§ **Listen to the narrated story in `img-audio` folder.**

---

## ğŸ“Œ **Tech Stack**
- **Hugging Face Transformers** (`Salesforce/blip-image-captioning-base`)
- **OpenAI GPT-3.5 Turbo** (Story Generation)
- **Hugging Face TTS** (`espnet/kan-bayashi_ljspeech_vits`)
- **LangChain for AI Pipeline**
- **Streamlit for UI**
- **Python (Torch, Transformers, Requests, OpenAI API)**

---

## ğŸ›  **Installation & Setup**  


# 1ï¸âƒ£ Clone the Repository  
```sh
git clone https://github.com/FazilMammadli/VisionSpeakAI.git
cd VisionSpeakAI
```

# 2ï¸âƒ£ Install Dependencies
```sh
pip install -r requirements.txt
```

# 3ï¸âƒ£ Set Up API Keys
```sh
# Create a .env file in the root directory with the following:
echo "OPENAI_API_KEY=your-api-key" >> .env
echo "HUGGINGFACE_API_TOKEN=your-huggingface-token" >> .env
```

# 4ï¸âƒ£ Run the App
```sh
streamlit run app.py
```

## ğŸš€ Usage Guide
- Upload an image â†’ AI will analyze the image.  
- Wait for processing (few seconds).  
- Generated Story Appears (text output).  
- Click "Play" â†’ Listen to AI-narrated story.  

## ğŸ“Š Future Enhancements
ğŸ”¹ Live Camera Integration for real-time image processing.  
ğŸ”¹ More AI Models for better speech quality.  
ğŸ”¹ Language Expansion (more languages & accents).  
ğŸ”¹ Custom Voice Selection for AI narration.  



## â­ Support & Contributions
ğŸ’¡ If you like this **AI-powered Image-to-Speech Tool**, **drop a â­ on GitHub!**  
ğŸš€ Contributions are welcomeâ€”submit a **pull request!**  



